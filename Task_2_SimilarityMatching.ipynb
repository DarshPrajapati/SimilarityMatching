{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP231PcD+z3Kq4YFu4cHMTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarshPrajapati/SimilarityMatching/blob/main/Task_2_SimilarityMatching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB69tdN2f4pw",
        "outputId": "6d5d582d-48d8-40ca-9ca6-6e51fd37956f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting npm\n",
            "  Downloading npm-0.1.1.tar.gz (2.5 kB)\n",
            "Collecting optional-django==0.1.0\n",
            "  Downloading optional-django-0.1.0.tar.gz (9.5 kB)\n",
            "Building wheels for collected packages: npm, optional-django\n",
            "  Building wheel for npm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for npm: filename=npm-0.1.1-py3-none-any.whl size=3708 sha256=4b7c0e1ce18d8ff6ba412e2d044211e86d392765f6788e09b7fb1b1f4b39474a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/f4/b7/b04f66d1d583751776af2ce4fac55409c6f66d55965e57ee99\n",
            "  Building wheel for optional-django (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optional-django: filename=optional_django-0.1.0-py3-none-any.whl size=9978 sha256=d3f32da370d86d4baf4f94c02134a494aeebf7ba8c6030423ff1f8d6b9efb766\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/e9/a3/5e7d589f0ee51e0631361966ac9eb7f063d46f68669ced53b5\n",
            "Successfully built npm optional-django\n",
            "Installing collected packages: optional-django, npm\n",
            "Successfully installed npm-0.1.1 optional-django-0.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install npm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Skip to content\n",
        "Search or jump to…\n",
        "Pull requests\n",
        "Issues\n",
        "Marketplace\n",
        "Explore\n",
        " \n",
        "@DarshPrajapati \n",
        "DarshPrajapati\n",
        "/\n",
        "SimilarityMatching\n",
        "Private\n",
        "Code\n",
        "Issues\n",
        "Pull requests\n",
        "Actions\n",
        "Projects\n",
        "Security\n",
        "Insights\n",
        "Settings\n",
        "SimilarityMatching/main.py /\n",
        "@DarshPrajapati\n",
        "DarshPrajapati Update main.py\n",
        "Latest commit 350a8f9 40 minutes ago\n",
        " History\n",
        " 1 contributor\n",
        "82 lines (56 sloc)  1.49 KB\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "#reading text file\n",
        "def read_file(filename):\n",
        "\n",
        "\ttry:\n",
        "\t\twith open(filename, 'r') as f:\n",
        "\t\t\tdata = f.read()\n",
        "\t\treturn data\n",
        "\t\n",
        "\texcept IOError:\n",
        "\t\tprint(\"Error opening or reading input file: \", filename)\n",
        "\t\tSystemExit\n",
        "    \n",
        " #splitting using translation table\n",
        "translation_table = str.maketrans(string.punctuation+string.ascii_uppercase,\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
        "\n",
        " #returns a list of the words\n",
        "def get_words(text):\n",
        "\t\n",
        "\ttext = text.translate(translation_table)\n",
        "\tword_list = text.split()\n",
        "\t\n",
        "\treturn word_list\n",
        "\n",
        "#frequency of each word\n",
        "def count_freq(word_list):\n",
        "\t\n",
        "\tD = {}\n",
        "\t\n",
        "\tfor new_word in word_list:\n",
        "\t\t\n",
        "\t\tif new_word in D:\n",
        "\t\t\tD[new_word] = D[new_word] + 1\n",
        "\t\t\t\n",
        "\t\telse:\n",
        "\t\t\tD[new_word] = 1\n",
        "\t\t\t\n",
        "\treturn D\n",
        "\n",
        "#word frequnecy for each file\n",
        "def word_freq(f):\n",
        "\t\n",
        "\tline_list = read_file(f)\n",
        "\tword_list = get_words(line_list)\n",
        "\tfreq_mapping = count_freq(word_list)\n",
        "\n",
        "\treturn freq_mapping\n",
        "\n",
        "#dot product\n",
        "def dotProduct(D1, D2):\n",
        "\tSum = 0.0\n",
        "\t\n",
        "\tfor key in D1:\n",
        "\t\t\n",
        "\t\tif key in D2:\n",
        "\t\t\tSum += (D1[key] * D2[key])\n",
        "\t\t\t\n",
        "\treturn Sum\n",
        "\n",
        "#angle between 2 vectors\n",
        "def vector_angle(D1, D2):\n",
        "\tn=dotProduct(D1, D2)\n",
        "\td=math.sqrt(dotProduct(D1, D1)*dotProduct(D2, D2))\n",
        "\t\n",
        "\treturn math.acos(n/d)\n",
        "\n",
        "def docsimilarity(f1, f2):\n",
        "\n",
        "\tsorted_list_1 = word_freq(f1)\n",
        "\tsorted_list_2 = word_freq(f2)\n",
        "\tdistance = vector_angle(sorted_list_1, sorted_list_2)\n",
        "\t\n",
        "\tprint(\"Similarity score = %f (radians)\"% distance)\n",
        "  \n",
        "#driver code\n",
        "docsimilarity(r\"f1.txt\", r\"f2.txt\")\n",
        "© 2022 GitHub, Inc.\n",
        "Terms\n",
        "Privacy\n",
        "Security\n",
        "Status\n",
        "Docs\n",
        "Contact GitHub\n",
        "Pricing\n",
        "API\n",
        "Training\n",
        "Blog\n",
        "About\n",
        "Loading complete"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "exhzsBACK6f_",
        "outputId": "da33b2eb-bc35-4eba-e49b-5010e8673768"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0bb3de804af6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Skip to content\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "#reading text file\n",
        "def read_file(filename):\n",
        "\n",
        "\ttry:\n",
        "\t\twith open(filename, 'r') as f:\n",
        "\t\t\tdata = f.read()\n",
        "\t\treturn data\n",
        "\t\n",
        "\texcept IOError:\n",
        "\t\tprint(\"Error opening or reading input file: \", filename)\n",
        "\t\tSystemExit\n",
        "    \n",
        " #splitting using translation table\n",
        "translation_table = str.maketrans(string.punctuation+string.ascii_uppercase,\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
        "\n",
        " #returns a list of the words\n",
        "def get_words(text):\n",
        "\t\n",
        "\ttext = text.translate(translation_table)\n",
        "\tword_list = text.split()\n",
        "\t\n",
        "\treturn word_list\n",
        "\n",
        "#frequency of each word\n",
        "def count_freq(word_list):\n",
        "\t\n",
        "\tD = {}\n",
        "\t\n",
        "\tfor new_word in word_list:\n",
        "\t\t\n",
        "\t\tif new_word in D:\n",
        "\t\t\tD[new_word] = D[new_word] + 1\n",
        "\t\t\t\n",
        "\t\telse:\n",
        "\t\t\tD[new_word] = 1\n",
        "\t\t\t\n",
        "\treturn D\n",
        "\n",
        "#word frequnecy for each file\n",
        "def word_freq(f):\n",
        "\t\n",
        "\tline_list = read_file(f)\n",
        "\tword_list = get_words(line_list)\n",
        "\tfreq_mapping = count_freq(word_list)\n",
        "\n",
        "\treturn freq_mapping\n",
        "\n",
        "#dot product\n",
        "def dotProduct(D1, D2):\n",
        "\tSum = 0.0\n",
        "\t\n",
        "\tfor key in D1:\n",
        "\t\t\n",
        "\t\tif key in D2:\n",
        "\t\t\tSum += (D1[key] * D2[key])\n",
        "\t\t\t\n",
        "\treturn Sum\n",
        "\n",
        "#angle between 2 vectors\n",
        "def vector_angle(D1, D2):\n",
        "\tn=dotProduct(D1, D2)\n",
        "\td=math.sqrt(dotProduct(D1, D1)*dotProduct(D2, D2))\n",
        "\t\n",
        "\treturn math.acos(n/d)\n",
        "\n",
        "def docsimilarity(f1, f2):\n",
        "\n",
        "\tsorted_list_1 = word_freq(f1)\n",
        "\tsorted_list_2 = word_freq(f2)\n",
        "\tdistance = vector_angle(sorted_list_1, sorted_list_2)\n",
        "\t\n",
        "\tprint(\"Similarity score = %f (radians)\"% distance)\n",
        "  \n",
        "#driver code\n",
        "docsimilarity(r\"C:\\Users\\dhruv\\OneDrive\\Desktop\\Test\\f1.txt\", r\"C:\\Users\\dhruv\\OneDrive\\Desktop\\Test\\f2.txt\")\n"
      ],
      "metadata": {
        "id": "ytEDtOOygTGb",
        "outputId": "80e56c98-5ca5-4dd7-ba65-128e0aa7729a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error opening or reading input file:  C:\\Users\\dhruv\\OneDrive\\Desktop\\Test\\f1.txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-00f40abf8ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#driver code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mdocsimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"C:\\Users\\dhruv\\OneDrive\\Desktop\\Test\\f1.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\"C:\\Users\\dhruv\\OneDrive\\Desktop\\Test\\f2.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-00f40abf8ddd>\u001b[0m in \u001b[0;36mdocsimilarity\u001b[0;34m(f1, f2)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdocsimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0msorted_list_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msorted_list_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_list_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_list_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-00f40abf8ddd>\u001b[0m in \u001b[0;36mword_freq\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mline_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mfreq_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-00f40abf8ddd>\u001b[0m in \u001b[0;36mget_words\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'translate'"
          ]
        }
      ]
    }
  ]
}